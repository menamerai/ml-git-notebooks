{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72266b3e-b229-4f26-9a8e-e8b6971817c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "Let's say that we want to perform a linear regression on a housing dataset to predict housing price.\n",
    "\n",
    "Let's say that using sklearn or Excel to simply draw a regression line is beneath us.\n",
    "\n",
    "Let's say we want to build something from the ground up, with *forward passes*, *back-propagation* and *gradient*.\n",
    "\n",
    "That's a loooot of let's and say's. But a thousand miles journey start with one step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9b761-a0f9-4424-8ff4-29d6c72c884e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb59a46-f26d-4b46-87a7-8acef6edac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Specified imports\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7d10f6-b133-4582-89cd-fc386f12c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd9faac-abc8-45c3-bbbb-da5c75da191d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseValue  \n",
       "0    -122.23          4.526  \n",
       "1    -122.22          3.585  \n",
       "2    -122.24          3.521  \n",
       "3    -122.25          3.413  \n",
       "4    -122.25          3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali = fetch_california_housing()\n",
    "df = pd.DataFrame(cali.data, columns=cali.feature_names)\n",
    "df['MedHouseValue'] = pd.Series(cali.target) # add y to df for convenience\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e93a0e-eec1-4fcc-8f10-09d87e919fac",
   "metadata": {},
   "source": [
    "For ease of computation, let's normalize the data down to a 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d15e92b-c524-43e2-bcd9-1c873d656136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.043512</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.567481</td>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.902266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538027</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>0.018929</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.565356</td>\n",
       "      <td>0.212151</td>\n",
       "      <td>0.708247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.210159</td>\n",
       "      <td>0.695051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.672783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "      <td>0.674638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  0.539668  0.784314  0.043512   0.020469    0.008941  0.001499  0.567481   \n",
       "1  0.538027  0.392157  0.038224   0.018929    0.067210  0.001141  0.565356   \n",
       "2  0.466028  1.000000  0.052756   0.021940    0.013818  0.001698  0.564293   \n",
       "3  0.354699  1.000000  0.035241   0.021929    0.015555  0.001493  0.564293   \n",
       "4  0.230776  1.000000  0.038534   0.022166    0.015752  0.001198  0.564293   \n",
       "\n",
       "   Longitude  MedHouseValue  \n",
       "0   0.211155       0.902266  \n",
       "1   0.212151       0.708247  \n",
       "2   0.210159       0.695051  \n",
       "3   0.209163       0.672783  \n",
       "4   0.209163       0.674638  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(df): # code I stole from StackOverflow\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "norm_df = normalize(df)\n",
    "norm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20624b9f-7d85-42b0-b0b5-70650a1d0ead",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Regression Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93993c06-d9a5-4faa-b7ea-a38e555c2709",
   "metadata": {
    "tags": []
   },
   "source": [
    "Linear Regression is often shown as the function:\n",
    "\n",
    "$y_i = β_0 + β_1 × x_1 + ... + β_n × x_k$\n",
    "\n",
    "Term $β_0$ is the \"baseline\" prediction, aka the prediction that is made when all of the features are 0. The numeric value of our target, in this case `MedHouseValue` is the combination of the *k* features of a row, or observation. Specifically, for each observation, a house, we have 8 features.\n",
    "\n",
    "$X=\\begin{bmatrix}x_1 & x_2 & ... & x_8\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5f2ec-3987-4496-86e7-4e5657536df6",
   "metadata": {},
   "source": [
    "With that background, our linear regression would look like this computationally:\n",
    "\n",
    "![Single Linear Reg](./imgs/2-2-chap2.png)\n",
    "\n",
    "The *M* function box would multiply the corresponding feature and weight pair together, which then are all added together with a bias in the *A* function box. Finally, the $\\Lambda$ function box calculate the error, or in our case, Squared Error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff134d8b-5c66-4cc6-a0fd-904a10c84bf7",
   "metadata": {},
   "source": [
    "This is fine and all, but we can combine the *M* and *A* box into a single matrix multiplication function with a little shift in thinking. Let's compose all the weights into a single column vector, \n",
    "\n",
    "$W=\\begin{bmatrix}w_1 \\\\ w_2 \\\\ ... \\\\ w_8\\end{bmatrix}$\n",
    "\n",
    "Then our prediction would simply be $p = X × W + \\beta = x_1 × w_1 + x_2 × w_2 + ... + x_8 + w_8 + \\beta$\n",
    "\n",
    "We can train in batches, so a batch of size 3 would look like:\n",
    "\n",
    "$X_{batch}=\\begin{bmatrix}x_{11} & x_{12} & ... & x_{18} \\\\ x_{21} & x_{22} & ... & x_{28} \\\\ x_{31} & x_{32} & ... & x_{38}\\end{bmatrix} = \\begin{bmatrix}X_1 \\\\ X_2 \\\\ X_3\\end{bmatrix}$\n",
    "\n",
    "$p_{batch}= X_{batch} × W + \\beta = \\begin{bmatrix}X_1 × W + \\beta \\\\ X_2 × W + \\beta \\\\ X_3 × W + \\beta\\end{bmatrix}$\n",
    "\n",
    "When we represent the forward phase this way, we also need to remodel the $\\Lambda$ box so that it returns a single value instead of an n (batch size) by 1 column vector. Just taking the mean of the row entries of the loss column vector is sufficient, so from that we have the function Mean Square Error (MSE).\n",
    "\n",
    "Using this paradigm shift, our new computational graph looks like this:\n",
    "\n",
    "![Matrix Linear Reg](./imgs/2-4-chap2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40ac62-db22-47f0-942a-2427ce004595",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Regression Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6757c10a-bd62-4193-882d-4797ee221519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X_batch, y_batch, weights, bias):\n",
    "    \"\"\"\n",
    "    Perform forward pass for linear regression according to the matrix multiplication computational graph\n",
    "    \"\"\"\n",
    "    \n",
    "    assert X_batch.shape[1] == y_batch.shape[0]\n",
    "    assert X_batch.shape[1] == weights.shape[0]\n",
    "    assert bias.shape[0] == bias.shape[1] == 1\n",
    "    \n",
    "    info = {}\n",
    "    \n",
    "    X_batch = np.array(X_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    \n",
    "    N = np.dot(X_batch, y_batch) # nu\n",
    "    P = N + bias # prediction\n",
    "    \n",
    "    loss = np.mean(np.power(y_batch - P, 2)) # mse\n",
    "    \n",
    "    info['X'] = X_batch\n",
    "    info['N'] = N\n",
    "    info['P'] = P\n",
    "    info['y'] = y_batch\n",
    "    \n",
    "    return loss, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc329391-d4f1-4bc0-8aac-ddff678bf05c",
   "metadata": {},
   "source": [
    "## Linear Regression Gradient Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6114e0b-0662-4c28-9030-76dfd978c7a1",
   "metadata": {},
   "source": [
    "Since the “forward pass” of this function was passing the input through a series of nested functions, the backward pass will simply involve computing the *partial derivatives* of each function, evaluating those derivatives at the functions’ inputs, and multiplying them together.\n",
    "\n",
    "![Gradient Calc Linear Reg](./imgs/2-5-chap2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d2e7f-7aef-4aa3-ac29-c1b8744b0112",
   "metadata": {},
   "source": [
    "Let's start at the top. So we want to first evaluate $\\frac{\\partial\\Lambda}{\\partial P}$ at its input P and y. Then we want to evaluate $\\frac{\\partial\\alpha}{\\partial N}$ at N & B, then $\\frac{\\partial\\nu}{\\partial W}$ at X & W. Finally, we multiply all of these derivatives together to obtain the *gradient* to update the weight (W) vector.\n",
    "\n",
    "$\\frac{\\partial\\Lambda}{\\partial P}(P, y) × \\frac{\\partial\\alpha}{\\partial N}(N, B) ×\\frac{\\partial\\nu}{\\partial W}(X, W)$\n",
    "\n",
    "We can repeat this process with $\\frac{\\partial\\Lambda}{\\partial P}(P, y) × \\frac{\\partial\\alpha}{\\partial B}(N, B)$ for the bias term B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb104ad8-9b81-4d68-a9ca-830d1a7f6f15",
   "metadata": {},
   "source": [
    "Let's first evaluate $\\frac{\\partial\\Lambda}{\\partial P}(P, y)$. Since $\\Lambda(P, y) = (y - P)^2$ for each element in P and y,\n",
    "\n",
    "$\\frac{\\partial\\Lambda}{\\partial P}(P, y) = -1 × 2 * (y - P)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578a48d-d91b-41b4-85d1-65c92c315fad",
   "metadata": {},
   "source": [
    "Now for $\\frac{\\partial\\alpha}{\\partial N}(N, B)$. Since $\\alpha$ is just addition, increasing any element of N by 1 would increase the corresponding entry in $\\alpha(N, B)$ by 1. Therefore, because N is a column vector, $\\frac{\\partial\\alpha}{\\partial N}(N, B)$ is also a column vector with every entries equal to 1. Using the same reasoning, $\\frac{\\partial\\alpha}{\\partial B}(N, B) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099f14e-d702-45ee-a158-a77e36d4d3e9",
   "metadata": {},
   "source": [
    "Finally, $\\frac{\\partial\\nu}{\\partial W}(X, W)$. This is very tricky, but due to how the multiplication work out, the partial derivative evaluates to $W^T$. In general, this simplification is applicable when computing derivatives of nested functions where one of the constituent functions is a matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282f52e-eb2c-4b5d-8d78-7801b2709372",
   "metadata": {},
   "source": [
    "In conclusion, we have:\n",
    "\n",
    "Gradients for W $=\\frac{\\partial\\Lambda}{\\partial P}(P, y) × \\frac{\\partial\\alpha}{\\partial N}(N, B) ×\\frac{\\partial\\nu}{\\partial W}(X, W) = -1 × 2 * (y - P) × \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\\\ \\vdots \\\\ 1\\end{bmatrix} × W^T$\n",
    "\n",
    "and\n",
    "\n",
    "Gradient for B $=\\frac{\\partial\\Lambda}{\\partial P}(P, y) × \\frac{\\partial\\alpha}{\\partial B}(N, B) = -1 × 2 * (y - P) × 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2802e-4fe5-4def-b2b6-823eff8bd993",
   "metadata": {},
   "source": [
    "## Linear Regression Gradients Calculation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940641d1-d413-48cf-83fe-9cf1bf913180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_gradients_calc(forward_info, weights, bias):\n",
    "    \"\"\"\n",
    "    Compute dLdW and dLdB for linear regression\n",
    "    \"\"\"\n",
    "    \n",
    "    dLdP = -1 * 2 * (forward_info['y'] - forward_info['P'])\n",
    "    dPdN = np.ones_like(forward_info['N'])\n",
    "    dPdB = 1\n",
    "    dNdW = np.transpose(weights, (1, 0))\n",
    "    \n",
    "    dLdN = dLdP * dPdN\n",
    "    dLdW = np.dot(dNdW, dLdN) # do this in this particular way to get singular number\n",
    "    \n",
    "    dLdB = (dLdP * dPdB).sum(axis=0) # also to get singular number\n",
    "    \n",
    "    loss_grads = {}\n",
    "    loss_grads['W'] = dLdW\n",
    "    loss_grads['B'] = dLdB\n",
    "    \n",
    "    return loss_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c3de2-165a-4455-8b07-a89e4a52b734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
